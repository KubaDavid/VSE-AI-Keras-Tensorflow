{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KubaDavid/VSE-AI/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIdyQBktbE8m"
      },
      "source": [
        "# Semestral work Keras and Tensor\n",
        "This is the last semestral work from VÅ E AI 4IZ231\\\n",
        "@authors Kotzias et. al (2015) and Zamazal (2020)\\\n",
        "@editor Jakub David\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziVBg2XfX6N0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "And the sound quality is great.:1\n"
          ]
        }
      ],
      "source": [
        "# Reading data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dfAmazon = pd.read_csv('amazon_cells_labelled.csv', names=['sentence', 'label'], sep='\\t')\n",
        "\n",
        "sentences = dfAmazon['sentence'].values\n",
        "\n",
        "labels = dfAmazon['label'].values\n",
        "labels = labels.astype(int)\n",
        "\n",
        "\n",
        "# Checking the data format\n",
        "print(sentences.shape)\n",
        "print(labels.shape)\n",
        "print(\"{}:{}\".format(sentences[10], labels[10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(600,)\n",
            "(600,)\n",
            "It lasts less than 3o minutes, if I actually try to use the phone.My wife has the same phone with the same problem.:0\n",
            "(150,)\n",
            "(150,)\n",
            "The cable looks so thin and flimsy, it is scary.:0\n",
            "(250,)\n",
            "(250,)\n",
            "Disappointing accessory from a good manufacturer.:0\n"
          ]
        }
      ],
      "source": [
        "# Dividing to train, test and validation datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sentences_train, sentences_test, labels_train, labels_test = train_test_split(sentences, labels, test_size=0.25, random_state=1000)\n",
        "sentences_train, sentences_val, labels_train, labels_val = train_test_split(sentences_train, labels_train, test_size=0.2, random_state=1000)\n",
        "\n",
        "# Data check\n",
        "print(sentences_train.shape)\n",
        "print(labels_train.shape)\n",
        "print(\"{}:{}\".format(sentences_train[9], labels_train[9]))\n",
        "print(sentences_val.shape)\n",
        "print(labels_val.shape)\n",
        "print(\"{}:{}\".format(sentences_val[9], labels_val[9]))\n",
        "print(sentences_test.shape)\n",
        "print(labels_test.shape)\n",
        "print(\"{}:{}\".format(sentences_test[9], labels_test[9]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65\n",
            "518\n",
            "1029\n",
            "It lasts less than 3o minutes, if I actually try to use the phone.My wife has the same phone with the same problem.\n",
            "(600, 1352)\n",
            "  (0, 11)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 540)\t1\n",
            "  (0, 581)\t1\n",
            "  (0, 624)\t1\n",
            "  (0, 654)\t1\n",
            "  (0, 664)\t1\n",
            "  (0, 743)\t1\n",
            "  (0, 768)\t1\n",
            "  (0, 856)\t1\n",
            "  (0, 900)\t1\n",
            "  (0, 1001)\t1\n",
            "  (0, 1153)\t1\n",
            "  (0, 1156)\t1\n",
            "  (0, 1185)\t1\n",
            "  (0, 1212)\t1\n",
            "  (0, 1244)\t1\n",
            "  (0, 1312)\t1\n",
            "  (0, 1322)\t1\n",
            "(150, 1352)\n",
            "  (0, 65)\t1\n",
            "  (0, 178)\t1\n",
            "  (0, 466)\t1\n",
            "  (0, 622)\t1\n",
            "  (0, 624)\t1\n",
            "  (0, 687)\t1\n",
            "  (0, 1080)\t1\n",
            "  (0, 1156)\t1\n",
            "(250, 1352)\n",
            "  (0, 334)\t1\n",
            "  (0, 488)\t1\n",
            "  (0, 518)\t1\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing into Bag of Words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "vectorizer.fit(sentences_train)\n",
        "\n",
        "# Check\n",
        "print(vectorizer.vocabulary_['and'])\n",
        "print(vectorizer.vocabulary_['good'])\n",
        "print(vectorizer.vocabulary_['service'])\n",
        "print(sentences_train[9])\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_val = vectorizer.transform(sentences_val)\n",
        "X_test = vectorizer.transform(sentences_test)\n",
        "\n",
        "# Check\n",
        "print(X_train.shape)\n",
        "print(X_train[9, :])\n",
        "print(X_val.shape)\n",
        "print(X_val[9, :])\n",
        "print(X_test.shape)\n",
        "print(X_test[9, :])\n",
        "\n",
        "y_train = labels_train\n",
        "y_val = labels_val\n",
        "y_test = labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convolution network\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "# Number of attributes\n",
        "input_dim = X_train.shape[1]\n",
        "print(input_dim)\n",
        "\n",
        "# Convolution network\n",
        "convolutionModel = Sequential()\n",
        "convolutionModel.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "convolutionModel.add(layers.Dense(1, activation='sigmoid'))\n",
        "convolutionModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "convolutionModel.summary()\n",
        "\n",
        "# Single layer network\n",
        "singleModel = Sequential()\n",
        "singleModel.add(layers.Dense(1, input_dim=input_dim, activation='sigmoid'))\n",
        "singleModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "singleModel.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN/Yl70GBrWn2gUIVcRuFIs",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
